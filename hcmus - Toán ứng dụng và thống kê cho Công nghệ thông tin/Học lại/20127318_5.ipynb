{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfe8863",
   "metadata": {},
   "source": [
    "### MSSV: 20127318\n",
    "### Học và tên: Phan Trí Tài ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import *\n",
    "from operator import itemgetter\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "name_col = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\n",
    "            \"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "\n",
    "def LR_all_feature(df):\n",
    "    train, test = train_test_split(df,test_size=0.1,shuffle = True)\n",
    "    feature = train.to_numpy()[:, 0:-1]\n",
    "    label = train.to_numpy()[:, -1:]\n",
    "\n",
    "    test_feature = test.to_numpy()[:, 0:-1]\n",
    "    test_label = test.to_numpy()[:, -1:]\n",
    "\n",
    "    x0 = np.ones((feature.shape[0],1))\n",
    "    feature = np.concatenate((x0,feature), axis = 1)\n",
    "    x_hat = np.linalg.pinv(feature) @ label\n",
    "    score = (np.linalg.norm(test_feature @ x_hat[1:,:] + x_hat[0:1,:] - test_label) ** 2)\n",
    "    print(x_hat)\n",
    "    print(score)\n",
    "    return x_hat\n",
    "\n",
    "\n",
    "def LR_one_feature(df):\n",
    "    gen = (each for each in name_col if each != 'quality')\n",
    "    data_score = []\n",
    "    X = []\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train_index, validation_index in kf.split(df):\n",
    "        train_data = df.iloc[train_index]\n",
    "        valid_data = df.iloc[validation_index]\n",
    "        for each in gen:\n",
    "            temp_train = train_data.loc[:,[each,'quality']]\n",
    "            x0 = np.ones((temp_train.shape[0], 1))\n",
    "            one_feature_data = np.concatenate((x0,temp_train),axis = 1)\n",
    "            A_train = one_feature_data[:, 0:-1]\n",
    "            label_train = one_feature_data[:, -1:]\n",
    "            x_hat = np.linalg.pinv(A_train) @ label_train\n",
    "            X.append(x_hat)\n",
    "\n",
    "            temp_valid = valid_data.loc[:, [each, 'quality']]\n",
    "            A_valid = temp_valid.loc[:,[each]]\n",
    "            label_valid = temp_valid.loc[:,['quality']]\n",
    "            A_valid = A_valid.to_numpy()\n",
    "            label_valid = label_valid.to_numpy()\n",
    "            data_score.append(np.linalg.norm(A_valid @ x_hat[1:,:] + x_hat[0:1,:] -  label_valid) ** 2)\n",
    "    min_index = min(enumerate(data_score), key=itemgetter(1))[0]\n",
    "    print(X)\n",
    "    print(data_score)\n",
    "    print(data_score[min_index])\n",
    "    return (name_col[min_index], X[min_index])\n",
    "\n",
    "def autoencoder(df):\n",
    "    feature = df.to_numpy()[:, 0:-1]\n",
    "    label = df.to_numpy()[:, -1:]\n",
    "    input_data = Input(shape=(11,))\n",
    "    encoded = Dense(6, activation='relu')(input_data)\n",
    "    decoded = Dense(11, activation=None)(encoded)\n",
    "\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    opt = optimizers.Adam(learning_rate=1e-3)\n",
    "    autoencoder.compile(optimizer=opt, loss='mse')\n",
    "    callback = callbacks.EarlyStopping(monitor='loss', mode = 'min')\n",
    "    autoencoder.fit(feature, feature,\n",
    "                    epochs = 500,\n",
    "                    shuffle=False,\n",
    "                    callbacks=callback)\n",
    "    bottle_neck = K.function([autoencoder.layers[0].input],[autoencoder.layers[1].output])\n",
    "    layer_output = bottle_neck([feature])\n",
    "\n",
    "    train_data, test_data = train_test_split(layer_output[0],test_size=0.1,shuffle=False)\n",
    "    train_label, test_label = train_test_split(label,test_size=0.1,shuffle=False)\n",
    "    x0 = np.ones((train_data.shape[0], 1))\n",
    "    A_train = np.concatenate((x0,train_data),axis = 1)\n",
    "    x_hat = np.linalg.pinv(A_train)@ train_label\n",
    "    score = (np.linalg.norm(test_data @ x_hat[1:,:] + x_hat[0:1,:] - test_label) ** 2)\n",
    "    print(score)\n",
    "    print(x_hat)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('wine.csv',sep = ';')\n",
    "    data = df.to_numpy()\n",
    "    feature = df.to_numpy()[:,0:-1]\n",
    "    label = df.to_numpy()[:,-1:]\n",
    "    # LR_all_feature(df)\n",
    "    # LR_one_feature(df)\n",
    "    autoencoder(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b632ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
